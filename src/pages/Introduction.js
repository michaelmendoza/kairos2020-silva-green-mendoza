import React from 'react';
import headerimage from '../images/introduction.png';

function Introduction() {
  return (
      <section className="section-article">
        <img src={headerimage} alt="header"/>
        <h1>Introduction</h1>
        <article>
          <p> 
            It has become almost rote to say that now, more than ever, students need to understand how to
            navigate web content to find verifiable and reliable information sources. While the data-collection
            portion of this study took place in the aftermath of the 2016 American presidential election, with
            students, and the public, increasingly confused about #fakenews and what media sources to trust to
            disseminate information (Raine and Anderson, 2017), structural revisions of this article took place during
            the Covid19 outbreak in the United States. As university campuses closed around the country, students,
            professors, and librarians alike headed home to watch the stories unfold online. As the outbreak evolved
            quickly, so did misinformation, partial information, and well-meaning, but bad, information. Will
            ibuprofen make me more likely to be hospitalized if I get Coronavirus? Can I make my own hand
            sanitizer? Are young people dying from the illness? Will a mask help? These questions, and varied
            answers to them, spread like wildfire on the open web, with people grasping for any semblance of an
            answer during a time when answers were as scarce as toilet paper. As trained information professionals
            watching the pandemic break, we observed, in interest, and also unease, as information spread faster
            than the illness itself. We wondered how students were receiving this information about something so
            exigent, so timely. We continue to wonder if educators are any surer than their students in their
            information-evaluation footing in such times of uncertainty and fear. Our research into source
            evaluation behaviors of first-year students, we realize, can give us some answers into how individuals
            interact with information online, and may be a beginning step to consider what composition courses can
            do to incorporate better media and information literacy pedagogy into curriculum.
          </p>
          <p>
            Those of us associated with first-year writing (FYW) students realize that many of them get their first
            formalized media and information literacy instruction in conjunction with first-year composition courses
            (Artman et al, 2010, p. 94). It remains difficult to ascertain, however, how
            exactly students are interacting with online content, and what, precisely, composition teachers and
            librarians should be teaching first-year students in their writing classes. How can curriculum respond to
            very real habits we see students new to the university enact in their information consumption
            behaviors?
          </p>
          <p>
            This webtext attempts to answer these questions using the results from a study of first-year composition
            students’ information evaluation behaviors as a basis for analysis and implications. In the summer of
            2017, we, the librarians associated with the composition program at Brigham Young University, tested
            twenty percent of the students enrolled in Writing 150, the university’s FYW course. We wanted to
            know how students go about determining how credible online information is. We were especially
            interested in information that is free and could easily be found through Google searches or social media.
            In other words, not academic articles hidden by publisher pay walls.
          </p>
          <p>
            As librarians, we wondered what made websites most and least reliable for students. We wondered if
            students would notice differences between mainstream and fringe web publications, or differences in
            article genres. Using a proctored survey, talk-aloud protocols, and screen recording, we observed source
            evaluation behaviors from first-year students, and then coded them using grounded theory. As we
            assessed our findings, we began to separate major trends into novice or expert-level evaluation
            behaviors based on previous research and our own expertise interacting with thousands of freshmen
            writers each year through library-run information literacy sessions.
          </p>
          <p>
            This webtext provides an interactive view of the landscape of our study. We picked five online sources
            which you can explore in the menu in conjunction with your reading of this text. Reading the text will be
            integral to your understanding of the interactive features. You will notice in your exploration that these
            are not the actual articles with which students completed the study. Given copyright constraints, we
            created mockup pages that work as stand-ins for the actual pages. The lorem ipsum text stands in for
            non-relevant parts of the article, and we have emphasized, in our design, any parts of the page that
            students engaged with in our coding of behaviors. We have linked the original pages to the mockups so
            you can compare and explore the original material as well. Our discussion, findings, and analysis are all
            underlined by the interactive features, and we will draw your attention to them as you read. After you
            read, and have the full context of the study, we invite you to explore the interactive features in full.
          </p>
          <p>
            Ultimately, we identify three pitfalls that arose from student source evaluation behaviors. These, we
            believe, are salient points of further investigation for librarians, educators, and compositionists alike.
            We complicate these pitfalls in the discussion section of the text, but here we offer you a brief overview
            of the issues you will see us returning to repeatedly as you read. As you move through this webtext, we
            invite you to consider how these pitfalls interact with one another and how educators might respond.
            We offer our own pedagogical implications in the final section of the webtext.
          </p>
          <ul>
            <li> 
              <b>First, there is a confusion over what constitutes authority online.</b> Students had difficulty following
              rules of thumb for information evaluation in the ever-changing landscape of the web. Who or
              what do they trust? As we transcribed each session, we could hear the confusion in their voices,
              and it was obvious in their justifications for what made the articles more or less reliable as
              well—students were very confused. We observed them struggle over what features are the
              most important to assess when it comes to authority, especially when some features seem to
              conflict with one another. Students had difficulty pinpointing what authority was credible and
              why.
            </li> 
            <li>
              Second, given the difficulty assessing authority, <b>students relied on their own assessments of
              credibility and reliability, oftentimes resulting in confirmation bias</b> and other problematic,
              short-sighted, narrow responses to the information presented. Such responses were not
              indicative of how the information existed in a wider context, but instead, within a very narrow,
              personally-inflected reading by the student. In response to conflicting feelings, emotions, or
              markers of credibility, students relied on pre-existing notions, emotional reactions, and instinctive
              responses to material.
            </li>
            <li>
              Third, also connected to difficulty ascertaining where authority is derived online, <b>students were
              easily seduced by visual rhetoric</b> like graphs, videos, and web design features. They believed that
              these were stand-ins for believability and trustworthiness, and as such, ignored more important
              markers when assessing information’s value, like if the information could be corroborated, was
              well-researched, or was disseminated by a trusted source. Such shallow source-evaluation
              behaviors bolster other research done in the domain of source evaluation. We make the further
              connection that this behavior is connected to the overall confusion over authority specifically.
            </li>
          </ul>
        </article>
      </section>
  );
}

export default Introduction;
